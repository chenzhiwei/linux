apiVersion: v1
kind: Pod
metadata:
  name: monitoring
spec:
  containers:
    - name: prometheus
      image: quay.io/prometheus/prometheus:latest
      imagePullPolicy: IfNotPresent
      # ports:
      #   - name: http
      #     containerPort: 9090
      volumeMounts:
        - name: prom-config
          mountPath: /etc/prometheus
        - name: prom-data
          mountPath: /prometheus
    - name: node-exporter
      image: quay.io/prometheus/node-exporter:latest
      imagePullPolicy: IfNotPresent
      # ports:
      #   - name: http
      #     containerPort: 9100
    - name: alertmanager
      image: quay.io/prometheus/alertmanager:latest
      imagePullPolicy: IfNotPresent
      # ports:
      #   - name: http
      #     containerPort: 9093
      volumeMounts:
        - name: alertmanager-config
          mountPath: /etc/alertmanager
        - name: alertmanager-data
          mountPath: /alertmanager
    - name: grafana
      image: docker.io/grafana/grafana:latest
      imagePullPolicy: IfNotPresent
      # ports:
      #   - name: http
      #     containerPort: 3000
  volumes:
    - name: prom-config
      configMap:
        name: prometheus
    - name: prom-data
      hostPath:
        path: /var/lib/prometheus
        type: DirectoryOrCreate
    - name: alertmanager-config
      configMap:
        name: alertmanager
    - name: alertmanager-data
      hostPath:
        path: /var/lib/alertmanager
        type: DirectoryOrCreate

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus
data:
  prometheus.yml: |-
    # my global config
    global:
      scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
      evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
      # scrape_timeout is set to the global default (10s).

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - localhost:9093

    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
      # - "first_rules.yml"
      # - "second_rules.yml"

    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'prometheus'

        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.

        static_configs:
        - targets: ['localhost:9090']

      - job_name: 'node'

        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.

        static_configs:
        - targets: ['localhost:9100']

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager
data:
  alertmanager.yml: |-
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://127.0.0.1:5001/'
    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'dev', 'instance']
